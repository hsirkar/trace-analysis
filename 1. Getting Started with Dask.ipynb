{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a711e31",
   "metadata": {},
   "source": [
    "# Getting Started with Dask\n",
    "\n",
    "**Dask** is a library for parallel computing in Python. It works by \"chunking\" large datasets into smaller datasets, and performing computations on the smaller datasets in parallel. For instance, it can break up a large Pandas DataFrame of 100k rows into 10 Pandas DataFrames of 10k rows. Then, when we want to perform some operation on the large 100k-row DataFrame, the Dask scheduler will schedule 10 tasks to be performed in parallel (in fact, it will determine and only schedule the tasks that are absolutely necessary for the final result).\n",
    "\n",
    "This notebook will get us accustomed to the way Dask works cooperatively with Pandas. It assumes familiarity with Pandas DataFrames and basic operations like indexing and aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb9ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f5ada",
   "metadata": {},
   "source": [
    "As seen in the above import, Dask has its own DataFrame, called Dask DataFrame. A Dask DataFrame is composed of a number of Pandas DataFrames, each representing a \"chunk\". We can specify the number of chunks when we initialize a Dask DataFrame.\n",
    "\n",
    "One way to initialize a Dask DataFrame is to take an existing Pandas DataFrame, and create a Dask DataFrame from that.\n",
    "\n",
    "So, let's first start by creating a dummy Pandas DataFrame (using a Pandas DatetimeIndex):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce875a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09 19:00:00</th>\n",
       "      <td>2395</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09 20:00:00</th>\n",
       "      <td>2396</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09 21:00:00</th>\n",
       "      <td>2397</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09 22:00:00</th>\n",
       "      <td>2398</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09 23:00:00</th>\n",
       "      <td>2399</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        a  b\n",
       "2021-09-01 00:00:00     0  a\n",
       "2021-09-01 01:00:00     1  b\n",
       "2021-09-01 02:00:00     2  c\n",
       "2021-09-01 03:00:00     3  a\n",
       "2021-09-01 04:00:00     4  d\n",
       "...                   ... ..\n",
       "2021-12-09 19:00:00  2395  a\n",
       "2021-12-09 20:00:00  2396  d\n",
       "2021-12-09 21:00:00  2397  d\n",
       "2021-12-09 22:00:00  2398  b\n",
       "2021-12-09 23:00:00  2399  e\n",
       "\n",
       "[2400 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.date_range(\"2021-09-01\", periods=2400, freq=\"1H\")\n",
    "df = pd.DataFrame({\"a\": np.arange(2400), \"b\": list(\"abcaddbe\" * 300)}, index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a42898",
   "metadata": {},
   "source": [
    "and then we can convert it to a Dask DataFrame. Our original Pandas DataFrame has 2400 rows. Let's set up the Dask DataFrame such that it has 10 partitions, each of 240 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b825cabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=10</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01 00:00:00</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-11 00:00:00</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 00:00:00</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09 23:00:00</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from_pandas, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                         a       b\n",
       "npartitions=10                    \n",
       "2021-09-01 00:00:00  int64  object\n",
       "2021-09-11 00:00:00    ...     ...\n",
       "...                    ...     ...\n",
       "2021-11-30 00:00:00    ...     ...\n",
       "2021-12-09 23:00:00    ...     ...\n",
       "Dask Name: from_pandas, 1 graph layer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dd.from_pandas(df, npartitions=10)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5f154",
   "metadata": {},
   "source": [
    "as you can see, a Dask DataFrame is really just a collection of Pandas DataFrames, each representing a chunk of the entire dataset. We can see the edges of the Pandas DataFrames (i.e. the index range of each partition) as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8166bdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2021-09-01 00:00:00', freq='H'),\n",
       " Timestamp('2021-09-11 00:00:00', freq='H'),\n",
       " Timestamp('2021-09-21 00:00:00', freq='H'),\n",
       " Timestamp('2021-10-01 00:00:00', freq='H'),\n",
       " Timestamp('2021-10-11 00:00:00', freq='H'),\n",
       " Timestamp('2021-10-21 00:00:00', freq='H'),\n",
       " Timestamp('2021-10-31 00:00:00', freq='H'),\n",
       " Timestamp('2021-11-10 00:00:00', freq='H'),\n",
       " Timestamp('2021-11-20 00:00:00', freq='H'),\n",
       " Timestamp('2021-11-30 00:00:00', freq='H'),\n",
       " Timestamp('2021-12-09 23:00:00', freq='H'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1a7fff",
   "metadata": {},
   "source": [
    "To access a specific partition, you can do it as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a5be1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-11</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-21</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: blocks, 2 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   a       b\n",
       "npartitions=1               \n",
       "2021-10-11     int64  object\n",
       "2021-10-21       ...     ...\n",
       "Dask Name: blocks, 2 graph layers"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.partitions[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2242fba",
   "metadata": {},
   "source": [
    "One cool thing about Dask is that when we set up an operation for it (like indexing or averaging), it won't immediately compute the result. It will setup the operation so that it can be computed when we need the result. If we want the result now, we have to explicitly specify that. This way, Dask can determine exactly which tasks it needs to do to get the final result, instead of greedily doing everything.\n",
    "\n",
    "For instance, let's say we want to define a 2D matrix, fill it with random values, and compute the average value across the first row. In regular Python or NumPy, we would have to generate the entire matrix, generate all the random values, and then compute the average value across the first row. We wasted time doing unnecessary work (i.e. generating the rest of the matrix). Dask, however, does not immediately generate the matrix. It waits until we need the result, and only does the work that's absolutely necessary (i.e. only fills the first row). It does this by building up a task graph, and dynamically ordering it based on the dependencies.\n",
    "\n",
    "That explains why above, we don't see the values of the Pandas DataFrame at partition 4. To actually see the results, we need to tell Dask explicitly to perform the computation, as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6df1c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-11 00:00:00</th>\n",
       "      <td>960</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 01:00:00</th>\n",
       "      <td>961</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 02:00:00</th>\n",
       "      <td>962</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 03:00:00</th>\n",
       "      <td>963</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 04:00:00</th>\n",
       "      <td>964</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-20 19:00:00</th>\n",
       "      <td>1195</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-20 20:00:00</th>\n",
       "      <td>1196</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-20 21:00:00</th>\n",
       "      <td>1197</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-20 22:00:00</th>\n",
       "      <td>1198</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-20 23:00:00</th>\n",
       "      <td>1199</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        a  b\n",
       "2021-10-11 00:00:00   960  a\n",
       "2021-10-11 01:00:00   961  b\n",
       "2021-10-11 02:00:00   962  c\n",
       "2021-10-11 03:00:00   963  a\n",
       "2021-10-11 04:00:00   964  d\n",
       "...                   ... ..\n",
       "2021-10-20 19:00:00  1195  a\n",
       "2021-10-20 20:00:00  1196  d\n",
       "2021-10-20 21:00:00  1197  d\n",
       "2021-10-20 22:00:00  1198  b\n",
       "2021-10-20 23:00:00  1199  e\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.partitions[4].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b3b7c6",
   "metadata": {},
   "source": [
    "Also, earlier, I did oversimplify a little bit by saying that a Dask DataFrame is *just* a collection of Pandas DataFrames. While that's true at its core, these Pandas DataFrames can easily work together if need be. For instance, we can index the Dask DataFrame without thinking of partitions, and Dask will schedule the tasks for each of the affected partitions to to their own indexing. Dask will then collect the result of these different tasks nicely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2661874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-01 00:00:00.000000000</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-09 05:00:59.999999999</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: loc, 2 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                                   a       b\n",
       "npartitions=1                               \n",
       "2021-10-01 00:00:00.000000000  int64  object\n",
       "2021-10-09 05:00:59.999999999    ...     ...\n",
       "Dask Name: loc, 2 graph layers"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf[\"2021-10-01\": \"2021-10-09 5:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d12581",
   "metadata": {},
   "source": [
    "Therefore, in most cases, we don't actually have to deal with the individual partitions. We can just perform operations on the big Dask DataFrame, and it will take care of scheduling the proper tasks for the proper partitions, as well as collecting the result to return to us in an expected format. In other words, **in many cases, we can just treat the Dask DataFrame like a Pandas DataFrame and expect it to work well** (the only difference being that we have to tell Dask to explicitly compute the result, which it otherwise doesn't do):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a27de62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-01 00:00:00</th>\n",
       "      <td>720</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01 01:00:00</th>\n",
       "      <td>721</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01 02:00:00</th>\n",
       "      <td>722</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01 03:00:00</th>\n",
       "      <td>723</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01 04:00:00</th>\n",
       "      <td>724</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-09 01:00:00</th>\n",
       "      <td>913</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-09 02:00:00</th>\n",
       "      <td>914</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-09 03:00:00</th>\n",
       "      <td>915</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-09 04:00:00</th>\n",
       "      <td>916</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-09 05:00:00</th>\n",
       "      <td>917</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       a  b\n",
       "2021-10-01 00:00:00  720  a\n",
       "2021-10-01 01:00:00  721  b\n",
       "2021-10-01 02:00:00  722  c\n",
       "2021-10-01 03:00:00  723  a\n",
       "2021-10-01 04:00:00  724  d\n",
       "...                  ... ..\n",
       "2021-10-09 01:00:00  913  b\n",
       "2021-10-09 02:00:00  914  c\n",
       "2021-10-09 03:00:00  915  a\n",
       "2021-10-09 04:00:00  916  d\n",
       "2021-10-09 05:00:00  917  d\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf[\"2021-10-01\": \"2021-10-09 5:00\"].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c350c8",
   "metadata": {},
   "source": [
    "Let's say we want to calculate the average of the `a` column in the entire Dask DataFrame. Normally, in Pandas, we would do `df[\"a\"].mean()`. In Dask, we can do the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a480c174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dd.Scalar<series-..., dtype=float64>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf[\"a\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c877d08",
   "metadata": {},
   "source": [
    "Well, what the heck is a `dd.Scalar`? Didn't you say that Dask will take care of dividing the work and collecting the result? \n",
    "\n",
    "That's correct, Dask will do that, but remember: we have to ask Dask to compute the result. A `dd.Scalar` is a lazy data structure -- it knows what work it has to do, but hasn't performed the work yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6633ffd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1199.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf[\"a\"].mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f2261",
   "metadata": {},
   "source": [
    "Similarly, let's do another operation -- this time, a cumulative sum and a subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8723d15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "2021-10-01 00:00:00.000000000    int64\n",
       "2021-10-09 05:00:59.999999999      ...\n",
       "Name: a, dtype: int64\n",
       "Dask Name: sub, 7 graph layers"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ddf[\"2021-10-01\": \"2021-10-09 5:00\"].a.cumsum() - 100\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec1fec",
   "metadata": {},
   "source": [
    "Again, the Dask Series is a lazy equivalent of the Pandas Series. If we need the results immediately, we can specify it as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a40e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-10-01 00:00:00       620\n",
       "2021-10-01 01:00:00      1341\n",
       "2021-10-01 02:00:00      2063\n",
       "2021-10-01 03:00:00      2786\n",
       "2021-10-01 04:00:00      3510\n",
       "                        ...  \n",
       "2021-10-09 01:00:00    158301\n",
       "2021-10-09 02:00:00    159215\n",
       "2021-10-09 03:00:00    160130\n",
       "2021-10-09 04:00:00    161046\n",
       "2021-10-09 05:00:00    161963\n",
       "Freq: H, Name: a, Length: 198, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621bd47",
   "metadata": {},
   "source": [
    "**To summarize:** Dask lets us perform parallel computing on different data structures, including Pandas DataFrames, by chunking the data structure into smaller subproblems, and solving the appropriate subproblems in parallel. Dask uses *lazy evaluation*, which means it doesn't execute tasks immediately when task are defined. Instead, it builds up a task graph (DAG), and only computes the result when explicitly specified. This way, it optimizes the execution plan, and only performs executions that are necessary for the final result.\n",
    "\n",
    "Dask also has its own scheduler, which is responsible for assigning tasks to available worker threads/processes, and ensuring that the dependencies in the task graph are satisfied.\n",
    "\n",
    "For more information about Dask DataFrames, I highly recommend you check out this doc page: https://docs.dask.org/en/stable/dataframe.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
